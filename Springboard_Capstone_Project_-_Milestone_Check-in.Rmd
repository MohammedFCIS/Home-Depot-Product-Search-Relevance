---
title: "Springboard Capstone Project - Milestone Check-in"
author: "/mohammed"
date: "February 27, 2016"
output: html_document
---

#Overview

Home Depot Product Search Relevance is Kaggle competition targets to improve Home Depot customers' shopping experience by developing a model that can accurately predict the relevance of search results.

Search relevancy is an implicit measure Home Depot uses to gauge how quickly they can get customers to the right products. Currently, human raters evaluate the impact of potential changes to their search algorithms, which is a slow and subjective process. By removing or minimizing human input in search relevance evaluation, the target is to predict the relevance for each pair listed in the test set. Given that the test set contains both seen and unseen search terms.

#The Data

This data set contains a number of products and real customer search terms from Home Depot's website. The challenge is to predict a relevance score for the provided combinations of search terms and products.

The relevance is a number between 1 (not relevant) to 3 (highly relevant). For example, a search for "AA battery" would be considered highly relevant to a pack of size AA batteries (relevance = 3), mildly relevant to a cordless drill battery (relevance = 2), and not relevant to a snow shovel (relevance = 1).
Let us explore the data together.
## Main product data

```{r, echo=FALSE}
suppressMessages(library(reader))
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(ggplot2)) 
suppressMessages(library(gridExtra))
```
Which include the following files:

- **train.csv** --> the training set, contains products, searches, and relevance scores.

- **test.csv** --> the test set, data will be used to submitting to the Kaggle competition.
 
```{r}
# Read training data first
products_training <- tbl_df(read.csv("data/train.csv", stringsAsFactors = FALSE))
# Have a quick glimpese on it
glimpse(products_training)
```
### Relevance Distribution
```{r}
# Read relevance data
relevance_dist <- products_training %>% count(as.factor(relevance))  %>% arrange(desc(n))
relevance_dist
#Let us explore the distribution
ggplot(products_training, aes(x = relevance)) +
   geom_histogram(color = "black", fill = "DarkOrange") +
  scale_x_continuous(breaks = seq(0, 3, 0.2))
```

```{r}
# Desnisty function
ggplot(products_training, aes(x = relevance)) +
   geom_density(color = "black") +
  scale_x_continuous(breaks = seq(0, 3, 0.2))
```

Looks like most search terms could score relevance score of **3** and a little of **1.25**.
```{r}
# Now we can read test data
products_test <- tbl_df(read.csv("data/test.csv",stringsAsFactors = FALSE))
```

```{r}
#combine training and test data, Joining by: c("id", "product_uid", "product_title", "search_term")
suppressMessages(product_training_test<- full_join(products_training,products_test))
```

```{r}
# Read product description
product_description <- tbl_df(read.csv("data/product_descriptions.csv",stringsAsFactors = FALSE))
glimpse(product_description)
#combine test data and data combined at the previous steps,Joining by: c("product_uid")
suppressMessages(product_all <- right_join(product_training_test, product_description))
#data after merging training, test and description datasets
glimpse(product_all)
```
### Let us figure out the most search term used
```{r}
#Now let us find out the most searched terms
product_all %>% count(search_term)  %>% arrange(desc(n))
#Let us have a nice histogram about it

```
### Let us figure out the most searched product
```{r}
product_all %>% count(product_uid)  %>% arrange(desc(n))

```

```{r}
#Read the attributes of products
products_attributes <- tbl_df(read.csv("data/attributes.csv",stringsAsFactors = FALSE, na.strings = 'N/A'))
glimpse(products_attributes)
```

```{r}
products_attributes <- products_attributes  %>%
                       filter(product_uid != 'NA') %>% #revmove null rows
                       unite(property, c(name,value), sep = ';;')   #combine name and values columns
glimpse(products_attributes)
```

```{r}
# group rows with the same id
products_attributes <- aggregate(products_attributes$property ~ products_attributes$property, by=list(products_attributes$product_uid), FUN=paste, collapse="@@@@")
glimpse(products_attributes)
```

```{r}
#restore original names
products_attributes <- products_attributes %>% rename(product_uid = Group.1, property = `products_attributes$property`)
glimpse(products_attributes)
```
#Generate new attribute fields and combine with 'product_all' 
```{r}
source('attributesParser.R')
products_attributes <- mutate(products_attributes, bullets = sapply(property, FUN = bulletsParser),
                                                   yeses = sapply(property, FUN = yesesParser),
                                                   nos = sapply(property, FUN = nosParser),
                                                   keys = sapply(property, FUN = keysParser),
                                                   values = sapply(property, FUN = valuesParser))
```

```{r}
#merge attributes with the main dataset
product_all <- full_join(product_all, products_attributes)
```
#Generate the features that will be used in linear regression
```{r}
source('matchScorer.R')
product_all <- mutate(product_all, bulletsScore = mapply(phrasesMatchScore, search_term, bullets),
                                   yesesScore   = mapply(phrasesMatchScore, search_term, yeses),
                                   nosScore     = mapply(phrasesMatchScore, search_term, nos),
                                   keysScore    = mapply(phrasesMatchScore, search_term, keys),
                                   valuesScore  = mapply(phrasesMatchScore, search_term, values))
```
# Divide the data into training and test sets
We divide the dataset back so can perform prediction and test our model
```{r}
product_all_train <- subset(product_all, !is.na(relevance))
product_all_test  <- subset(product_all, is.na(relevance))
```
#Performing linear regression
```{r}
RegModel = lm(relevance ~ bulletsScore + yesesScore + nosScore + keysScore + valuesScore, data = product_all_train)
TestPredictions = predict(RegModel, newdata = product_all_test)
```
#Test model investigation
```{r}
summary(RegModel)
```

## Output Relevance Distribution
```{r}
# Read relevance data
product_all_test$relevance <- as.numeric(TestPredictions)
relevance_dist_final <- product_all_test %>% count(as.factor(relevance))  %>% arrange(desc(n))
relevance_dist_final
#Let us explore the distribution
ggplot(product_all_test, aes(x = relevance)) +
   geom_histogram(color = "black", fill = "DarkOrange", bins = 12) +
  scale_x_continuous(breaks = seq(2, 3, 0.1))
```

* We could not help but notice that data is spread between **2.2** and **2.6** with max value is between **2.3** and **2.4**.
* The data is, nearly, normally distributed with an outlier in **2.5**.

Let us see another view
```{r}
# Desnisty function
relecance_graph <- ggplot(product_all_test, aes(x = relevance)) +
   geom_density(color = "black") +
  scale_x_continuous(breaks = seq(2, 3, 0.2))
```
It confirms our previous induction.

Let us now investigate the features used in the model to see their affect on the result
```{r}

bullets_graph <- ggplot(product_all_test, aes(x = bulletsScore))+
   geom_density(color = "black") +
   scale_x_continuous()
yeses_graph <- ggplot(product_all_test, aes(x = yesesScore))+
   geom_density(color = "black") +
   scale_x_continuous()
nos_graph <- ggplot(product_all_test, aes(x = nosScore))+
   geom_density(color = "black") +
   scale_x_continuous()
keys_graph <- ggplot(product_all_test, aes(x = keysScore))+
   geom_density(color = "black") +
   scale_x_continuous()
values_graph <- ggplot(product_all_test, aes(x = valuesScore))+
   geom_density(color = "black") +
   scale_x_continuous()
grid.arrange(bullets_graph, yeses_graph, nos_graph, keys_graph, values_graph, relecance_graph)

```

It seems that the builets score is one affects the outlier
```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

